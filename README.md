# Data Pipeline in Azure Databricks

## Overview
This project demonstrates the creation of a data pipeline using Azure Databricks. The pipeline includes data ingestion, processing, and storage.

## Pipeline Components
### Data Ingestion
_ Description: Data is ingested from a CSV file hosted on GitHub.
_ Screenshot: Include a screenshot of the data ingestion code in the Databricks notebook.
### Data Processing
_ Description: The data is grouped by scientific_name and counted.
Code Example: (Insert a brief snippet of your transformation code here)
Screenshot: Include a screenshot of the transformation code and its output in the notebook.
### Data Storage
_ Description: The processed data is stored in DBFS as a Parquet file.
Screenshot: Include a screenshot of the code used for writing the data to DBFS and the resulting file in DBFS.