# Data Pipeline in Azure Databricks

## Overview
This project demonstrates the creation of a data pipeline using Azure Databricks. The pipeline processes a dataset of bird observations, performing grouping and counting operations.

## Pipeline Components
### Data Ingestion
The data is ingested from a CSV file hosted on GitHub.
(Screenshot: Include a screenshot here of the data ingestion code in the Databricks notebook.)

### Data Processing
The data is grouped by scientific_name and counted.
(Screenshot: Include a screenshot here of the transformation code and its output in the notebook.)

### Data Storage
The processed data is stored in DBFS as a Parquet file.
(Screenshot: Include a screenshot here of the code used for writing the data to DBFS and the resulting file in DBFS.)

